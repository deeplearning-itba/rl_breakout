{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0ec626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'gym[atari]'\n",
    "# pip install 'stable-baselines3[extra]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d208ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23654f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.policies import CnnPolicy\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741b9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = 16\n",
    "env = make_vec_env(\"CartPole-v1\", n_envs=n_envs, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a4812a-ab8e-420a-8cb9-aa64470a59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5c4424-118d-4eb2-8410-0ba828b3c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97dc6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import gym\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.logger import Video\n",
    "\n",
    "\n",
    "class VideoRecorderCallback(BaseCallback):\n",
    "    def __init__(self, eval_env: gym.Env, render_freq: int, n_eval_episodes: int = 1, deterministic: bool = True):\n",
    "        \"\"\"\n",
    "        Records a video of an agent's trajectory traversing ``eval_env`` and logs it to TensorBoard\n",
    "\n",
    "        :param eval_env: A gym environment from which the trajectory is recorded\n",
    "        :param render_freq: Render the agent's trajectory every eval_freq call of the callback.\n",
    "        :param n_eval_episodes: Number of episodes to render\n",
    "        :param deterministic: Whether to use deterministic or stochastic policy\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._eval_env = eval_env\n",
    "        self._render_freq = render_freq\n",
    "        self._n_eval_episodes = n_eval_episodes\n",
    "        self._deterministic = deterministic\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self._render_freq == 0:\n",
    "            screens = []\n",
    "\n",
    "            def grab_screens(_locals: Dict[str, Any], _globals: Dict[str, Any]) -> None:\n",
    "                \"\"\"\n",
    "                Renders the environment in its current state, recording the screen in the captured `screens` list\n",
    "\n",
    "                :param _locals: A dictionary containing all local variables of the callback's scope\n",
    "                :param _globals: A dictionary containing all global variables of the callback's scope\n",
    "                \"\"\"\n",
    "                screen = self._eval_env.render(mode=\"rgb_array\")\n",
    "                # PyTorch uses CxHxW vs HxWxC gym (and tensorflow) image convention\n",
    "                screens.append(screen.transpose(2, 0, 1))\n",
    "\n",
    "            evaluate_policy(\n",
    "                self.model,\n",
    "                self._eval_env,\n",
    "                callback=grab_screens,\n",
    "                n_eval_episodes=self._n_eval_episodes,\n",
    "                deterministic=self._deterministic,\n",
    "            )\n",
    "            self.logger.record(\n",
    "                f\"trajectory/video_{self.n_calls}\",\n",
    "                Video(th.ByteTensor([screens]), fps=40),\n",
    "                exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
    "            )\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7a0af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"CartPole-v1\", n_envs=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0283d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    'MlpPolicy',\n",
    "    env, verbose=1, tensorboard_log=\"./a2c_cheeta_tensorboard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3991978a-cf20-4c38-9824-4fd00a3cc5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd91c093-9941-46de-bfbd-62a9b7a0dbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d3ce4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_recorder = VideoRecorderCallback(\n",
    "    make_vec_env(\"CartPole-v1\", n_envs=1, seed=0),\n",
    "    render_freq=5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4330f-b16f-4675-bbcc-74b66a45cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./a2c_cheeta_tensorboard/A2C_2\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 23.5     |\n",
      "|    ep_rew_mean        | 23.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.659   |\n",
      "|    explained_variance | -0.0279  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    value_loss         | 8.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.4     |\n",
      "|    ep_rew_mean        | 28.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.662   |\n",
      "|    explained_variance | 0.559    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    value_loss         | 6.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.2     |\n",
      "|    ep_rew_mean        | 34.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.629   |\n",
      "|    explained_variance | -0.0105  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    value_loss         | 6.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.7     |\n",
      "|    ep_rew_mean        | 40.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 538      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.606   |\n",
      "|    explained_variance | -0.0114  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    value_loss         | 5.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.7     |\n",
      "|    ep_rew_mean        | 47.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 631      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.599   |\n",
      "|    explained_variance | 0.0908   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 4.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 55.7     |\n",
      "|    ep_rew_mean        | 55.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.417   |\n",
      "|    explained_variance | 0.0315   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    value_loss         | 497      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.1     |\n",
      "|    ep_rew_mean        | 63.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 788      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | -0.0306  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.6     |\n",
      "|    ep_rew_mean        | 69.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 856      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | -0.00841 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 76.7     |\n",
      "|    ep_rew_mean        | 76.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 916      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.568   |\n",
      "|    explained_variance | -0.00587 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    value_loss         | 3.14     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(5e6), callback=video_recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c6226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f44a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    # By default, deterministic=False, so we use the stochastic policy\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
